/*! \page image-processing %Image Processing
 * ## Applying a %Filter to Your own %Image
 * To use the command-line %Image Processing tool on your own images, you first need to obtain the source code for this project. Please view \ref getting-started on how to obtain a local copy of the source code to get started. \ref getting-started has a section titled 'Running an %Image %Filter on An %Image (Command-Line Tool)' that describes how to compile and run the Image Processing command-line tool.
 * 
 * Once you have obtained a local copy of the source code on your local machine you are ready to run your own image filtering. 
 * 1. Start run the Docker container using the instructions in the **Build Docker Environment** section in \ref getting-started.
 * 2. Within your Docker container, navigate into the `project/ImageProcessing/` directory where the source code is located. This can be done by running the `cd project/ImageProcessing/` command.
 * 3. Run the command `make clean && make -j` to compile all of the source code required to run the %image processor.
 * 4. You are now ready to run the project using the following command: `./image_processor <inputImage> <filter> <outputImage>`
 * 	1. `<inputImage>` is a string that represents the relative path to the image that you want to apply a filter to (e.g. `"data/dog.png"`)
 * 	2. `<filter>` is a string that represents the type of filter that you want to apply to your image. The filter options include:
 *			1. greyscale - Applies a Greyscale filter to the `<inputImage>` specified.
 *			2. threshold - Applies a Threshold filter with a threshold of 0.50 to the `<inputImage>` specified.
 *			3. threshold-low - Applies a Threshold filter with a threshold of 0.25 to the `<inputImage>` specified.
 *			4. threshold-high - Applies a Threshold filter with a threshold of 0.75 to the `<inputImage>` specified.
 *			5. mean_blur - Applies a Mean Blur filter to the `<inputImage>` specified.
 *			6. gaussian - Applies a Gaussian Blur filter with a kernel size of 5 and a sigma value of 2 to the `<inputImage>` specified.
 *			7. double_threshold_filter - Applies a Double Threshold filter with a low threshold ratio of 0.10 and a high threshold ratio of 0.20 to the `<inputImage>` specified.
 *			8. hysteresis_filter - Applies a Hysteresis filter with a weak threshold of 25.0 and a strong threshold of 255.0 to the `<inputImage>` specified.
 *			9. canny-edge-detect - Applies a %Canny Edge Detection to the `<inputImage>` specified.
 * 	3. `<outputImage>` is a string that represents the relative path and file name of the image that will be generated by applying the specificed filter.
 * 
 * ## Adding Your Own Filters
 * Adding your own filters is relatively easy with this project. 
 * 1. Determine if the filter that you want to add fits into the category of a SimpleFilter, RelatedPixelFilter, or ConvolutionFilter based on the definitions above.
 *	1. If so, create a new class for your filter that is derived from the correct categoral class (SimpleFilter, RelatedPixelFilter, or ConvolutionFilter).
 *	2. If not, create a new categorical class for your new type of filter. This categorical class should be derived from the base Filter class.
 *			1. This new categorical class will need to implement the pure virtual `Apply` method as defined in the Filter class. Use the SimpleFilter, RelatedPixelsFilter, or ConvolutionFilter classes as templates for achieving this.
 * 2. Once your have a categorical class that is derived from Filter that is appropriate for your new filter, create a new derived class from the correct categorical class for your brand new filter. Your new class will need to implement the pure virtual `ApplyAtPixel` method as defined in your categorical class. This method describes what the image filter does to each pixel in the image to apply the filter. Use the SimpleFilter, RelatedPixelsFilter, or ConvolutionFilter classes as templates for achieving this.
 * 3. Within `ImageProcessor.h` include the header file for your newly defined filter class and add the filter to the map of strings and filters within the ImageProcessor constructor. Use the already defined filters as a template.
 * 4. Re-compile the source code using `make` as described in the **Running an %Image %Filter on An %Image** section above.
 * 5. Start applying your new filter to images!
 * 
 * ## %Image Processor Design Structure
 * 
 * All of the classes for this image processor iteration were created with the goal of designing code that is extensible, flexible and non-repetitive. 
 *  Polymorphism, encapsulation and inheritance were used to achieve those goals. The filter class was implemented to serve as the base for all derived
 *  filter classes. Categorial filter classes, such as RelatedPixelFilter, were created to categorize filters based on how they apply a filter to an image.
 *  This section aims to give a detailed description of the design implemented. 
 * 
 * Our design follows a facade design pattern, the complexity of the system is hidden and the ImageProcessor behaves as the interface for a user to interact with.
 *  The %Image Processor contains the possible filters that can be applied to an image, such as `greyscale` and `canny-edge-detect`, and has a dependency to Image, which 
 *  means that an Image is not held by the ImageProcessor but rather the ImageProcessor interacts with the Image class through the `ApplyFiler(...)` method based on any Filter
 *  type passed as an input parameter. For this iteration, we assumed that the `sobel` and `non-max` filters were only used if implementing the canny edge detection, 
 *  therefore the %Image Processor cannot directly implement these two filters. Moreover, it was assumed that any image passed to the %Image Processor as input existed. 
 * 
 * <img alt="Img class uml diagram" width="100%" src="../pages/images_uml/ImageClass.png">
 * 
 * 
 * Specifically, the design chosen to represent an image from the filesystem was as an instance of the Image class, in which each Color object represents a single pixel in the image, so an Image object contains
 *  a unique pointer to an array of Colors. 
 * 
 * <img alt="Color and IMG uml diagram" width="100%" src="../pages/images_uml/Color_Img.png">
 * 
 * Filter Class serves as the abstract base class from which 3 main categories are derived: SimpleFilter, RelatedPixelFilter and Canny. 
 * 
 * <img alt="Filter uml diagram" width="100%" src="../pages/images_uml/Filter_UML.png">
 * 
 * The SimpleFilter class is for filters that change a single image pixel without information about any other pixel in the image.
 *  Therefore, SimpleFilter serves as the abstract class for greyscale, double threshold, and threshold image filters. 
 * 
 * <img alt="Simple Filter uml diagram" width="100%" src="../pages/images_uml/SimpleFilter.png">
 * 
 * 
 * Additionally, the RelatedPixelFilter class is an abstract class for any filter that calculates the new, filtered pixel color components based
 *  on other pixels in the image. Two filters that are derived from this class and that have been implemented are the HysteresisFilter and the 
 *  NonMaxSupFilter to apply a hysteresis and non-maximum suppression filter to an image, respectively. Moreover, ConvolutionFilter is a subcategory
 *  of the RelatedPixelFilter abstract class since a convolution filter needs to take into account surrounding pixels to determine the filtered
 *  value of a pixel and a kernel to be applied to those surrounding pixels.  
 * 
 * <img alt="Related Pixel Filter uml diagram" width="100%" src="../pages/images_uml/RelatedPixelFilter.png">
 * 
 * Each instance of the ConvolutionFilter class has a vector of kernels. Kernel is a class that stores the matrix representing the kernel values that 
 *  need to be applied to the a pixel and its surrounding pixels to determine the new filtered pixel color values. This abstract ConvolutionFilter class
 *  serves as the basis for the GaussianFilter and the SobelFilter, which called the parent constructor to initialize their respective kernels.
 * 
 * <img alt="Convolution Filter uml diagram" width="100%" src="../pages/images_uml/ConvolutionFilter.png">
 * 
 * 
 * The last category of filters is the Canny filter, which implements the canny edge detection algorithm through the use of a composite pattern.
 * 
 * <img alt="Canny Filter uml diagram" width="100%" src="../pages/images_uml/Canny.png">
 * 
 * 
 * As mentioned above, all of the classes for this image processor iteration were created with the goal of designing code that is extensible, flexible
 *  and non-repetitive, thereby allowing for all of our code to be close to modification and open to extension. Adding a new filter is a straightforward process. First, determine if the filter that you want to add fits into the category of a SimpleFilter, RelatedPixelFilter,
 *  or ConvolutionFilter based on the definitions above. If it follows one of those definitions, create a new class for your filter that is derived from the correct
 *  categorical class (SimpleFilter, RelatedPixelFilter, or ConvolutionFilter). Your new Filter class will need to implement the `ApplyAtPixel(...)` method, which applies the given filter
 *  to a specific pixel (x,y). On the other hand, if it is a “new” categorical filterm create a class for your filter that inherits directly from Filter class. Note that
 *  this new categorical filter will need to implement the pure virtual `Apply(...)` method as defined in the Filter class.
 * 
 * 
 * Note, that although the explanation above uses our implementation of filters, the RescueSimulation uses the `opencv` library by creating an ObjectDetector 
 *  that implements the canny and edge detect filter via `opencv` directly to check if the robot was found. The reason behind this design choice was primarily speed. 
 *  Our implementation of canny edge detection took approximately 15 seconds, while the `opencv` library canny edge detection took less than 1 second.  Moreover, we created an ObjectDetector class
 *  rather than an image processor because we also needed to determine which pixel in the image the robot was found at. 
 * 
 * ## Copyright
 * &copy; 2021 Laura Arias Fernandez, Michael Weiner, and Malik Khadar  All rights reserved.
 */